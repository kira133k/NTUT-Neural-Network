# -*- coding: utf-8 -*-
"""Homework01-2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1J_1aqnVCT-LCmiACvs0kSs8lGaZJ3Wrw
"""

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

X = np.array([
    [-1, -0.5, -0.5, 0.3],
    [-1, -0.5,  0.5, 0.6],
    [-1,  0.3, -0.5, -0.1],
    [-1, -0.1,  1.0, -0.4]
])

d = np.array([1, 1, -1, -1])

class Perceptron:
    def __init__(self, learning_rate=0.1, epochs=10):
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.weights = None
        self.errors_ = []
        self.iteration_errors_ = []

    def activation(self, net_input):
        return 1 if net_input >= 0 else -1

    def fit(self, X, y):
        n_cols = X.shape[1]
        self.weights = np.zeros(n_cols)

        for epoch in range(self.epochs):
            misclassifications = 0

            for xi, target in zip(X, y):
                net_input = np.dot(xi, self.weights)
                predicted = self.activation(net_input)

                error = target - predicted
                self.iteration_errors_.append(error)

                if error != 0:
                    update = self.learning_rate * error
                    self.weights += update * xi
                    misclassifications += 1

            self.errors_.append(misclassifications)

        return self

perceptron = Perceptron(learning_rate=0.1, epochs=10)
perceptron.fit(X, d)
w = perceptron.weights
print("\n訓練完成後的最終權重:", w)

fig1 = plt.figure(figsize=(10, 8))
ax1 = fig1.add_subplot(111, projection='3d')

positive_samples = X[d == 1]
negative_samples = X[d == -1]

ax1.scatter(positive_samples[:, 1], positive_samples[:, 2], positive_samples[:, 3], c='dodgerblue', marker='+', s=150, linewidths=2.5, label='Positive samples')
ax1.scatter(negative_samples[:, 1], negative_samples[:, 2], negative_samples[:, 3], edgecolors='crimson', facecolors='none', marker='o', s=150, linewidths=2, label='Negative samples')

ax1.set_title('Classification Result')
ax1.legend(loc='upper left', fontsize=10)
ax1.set_xlabel("P(1)", fontsize=12, labelpad=15)
ax1.set_ylabel("P(2)", fontsize=12, labelpad=15)
ax1.set_zlabel("P(3)", fontsize=12, labelpad=15)
ax1.grid(True, linewidth=0.5, linestyle=':')

if w[3] != 0:
    x1_range = np.linspace(-1, 1, 10)
    x2_range = np.linspace(-1, 1, 10)
    x1_grid, x2_grid = np.meshgrid(x1_range, x2_range)
    x3_grid = (w[0] - w[1] * x1_grid - w[2] * x2_grid) / w[3]
    ax1.plot_surface(x1_grid, x2_grid, x3_grid, alpha=0.4, color='g')

ax1.view_init(elev=25, azim=295)
plt.show()

fig2, ax2 = plt.subplots(figsize=(12, 6))
iteration_range = range(1, len(perceptron.iteration_errors_) + 1)
ax2.plot(iteration_range, perceptron.iteration_errors_, marker='.', linestyle='-', color='purple', label='Error (target - predict)')

ax2.set_title("Error Iteration")
ax2.set_xlabel("Iteration")
ax2.set_ylabel("Error")
ax2.set_yticks(np.arange(-2, 2.1, 1))
ax2.grid(True, linestyle=':', linewidth=0.5, which='major')

plt.tight_layout()
plt.show()