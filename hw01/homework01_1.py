# -*- coding: utf-8 -*-
"""Homework01-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GavU3A948gzo3SpudHL9lbh5yHfEbIN8
"""

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

X = np.array([
    [-1, -0.5, -0.5],
    [-1, -0.5,  0.5],
    [-1,  0.3, -0.5],
    [-1, -0.1,  1.0]
])

d = np.array([1, 1, -1, -1])

class Perceptron:
    def __init__(self, learning_rate=0.1, epochs=10):
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.weights = None
        self.errors_ = []
        self.iteration_errors_ = []

    def activation(self, net_input):
        return 1 if net_input >= 0 else -1

    def fit(self, X, y):
        n_cols = X.shape[1]
        self.weights = np.zeros(n_cols)

        for epoch in range(self.epochs):
            misclassifications = 0

            for xi, target in zip(X, y):
                net_input = np.dot(xi, self.weights)
                predicted = self.activation(net_input)

                error = target - predicted
                self.iteration_errors_.append(error)

                if error != 0:
                    update = self.learning_rate * error
                    self.weights += update * xi
                    misclassifications += 1

            self.errors_.append(misclassifications)

        return self

perceptron = Perceptron(learning_rate=0.1, epochs=10)
perceptron.fit(X, d)
w = perceptron.weights
print("訓練完成後的最終權重:", w)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

positive_samples = X[d == 1]
negative_samples = X[d == -1]
ax1.scatter(positive_samples[:, 1], positive_samples[:, 2], c='dodgerblue', marker='+', s=150, linewidths=2.5, label='Positive samples')
ax1.scatter(negative_samples[:, 1], negative_samples[:, 2], edgecolors='crimson', facecolors='none', marker='o', s=150, linewidths=2, label='Negative samples')
ax1.set_title('Vectors to be Classified')
ax1.set_xlabel("P(1)", fontsize=10)
ax1.set_ylabel("P(2)", fontsize=10)

ax1.set_xlim(-1, 1)
ax1.set_ylim(-1.2, 1.7)

ax1.set_xticks(np.arange(-0.8, 1, 0.2))
ax1.set_yticks(np.arange(-1, 1.6, 0.5))
ax1.grid(True, linewidth=0.7, linestyle=':')

ax1.legend(loc='upper left', fontsize=10)
if w[2] != 0:
    x1_range = np.linspace(-1, 1, 10)
    x2_range = (-w[0] - w[1] * x1_range) / w[2]
    ax1.plot(x1_range, x2_range, color='g', linestyle='--', linewidth=2, label='Decision Boundary')
    ax1.legend()

iteration_range = range(1, len(perceptron.iteration_errors_) + 1)
ax2.plot(iteration_range, perceptron.iteration_errors_, marker='.', linestyle='-', color='purple')

ax2.set_title("Error Iteration")
ax2.set_xlabel("Iteration")
ax2.set_ylabel("Error")
ax2.set_yticks(np.arange(-2, 2.1, 1))
ax2.grid(True, linestyle=':', linewidth=0.5, which='major')

plt.tight_layout()
plt.show()